# GestureTalk: Real-Time Sign Language Communication System

## ðŸ“Œ Overview
GestureTalk is a **real-time sign language communication system** that enables two-way communication between deaf and hearing users.  
It uses **YOLO** and **DWpose** for gesture recognition, **3D avatar animation** for visual representation, and integrates **speech recognition** and **NLP** for smooth interaction.

## âœ¨ Features
- Real-time gesture recognition using YOLO & DWpose
- 3D avatar animation for realistic sign representation
- Speech-to-sign and sign-to-speech conversion
- NLP-based text processing for improved accuracy
- Optimized with OpenCV, PyTorch, and real-time inference pipelines

## ðŸ›  Tech Stack
- **Languages:** Python
- **Frameworks & Libraries:** PyTorch, OpenCV, Hugging Face Transformers, NLTK
- **Models:** YOLO, DWpose
- **APIs:** Google Speech-to-Text, Text-to-Speech

## ðŸ“‚ Project Structure
GestureTalk-Sign-Language-Recognition/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_videos/
â”‚   â””â”€â”€ dataset_links.txt
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov8_weights.pt
â”‚   â”œâ”€â”€ dwpose_model.pth
â”‚   â””â”€â”€ trained_model/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ gesture_recognition.py
â”‚   â”œâ”€â”€ speech_to_text.py
â”‚   â”œâ”€â”€ text_to_speech.py
â”‚   â”œâ”€â”€ avatar_animation.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_preprocessing.ipynb
â”‚   â””â”€â”€ model_training.ipynb
â””â”€â”€ docs/
    â”œâ”€â”€ architecture_diagram.png
    â””â”€â”€ usage_guide.md


